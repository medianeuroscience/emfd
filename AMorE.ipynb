{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moral Foundations Dictionary Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports -> these should go into the requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import re \n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "punctuation += '’'\n",
    "for i in range(0,10):\n",
    "    punctuation += str(i)\n",
    "    \n",
    "stopwords = set(list(nltk_stopwords) + list(ENGLISH_STOP_WORDS) + list(STOP_WORDS))\n",
    "from collections import Counter\n",
    "import re, fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MFDs and CSV with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load E-MFD\n",
    "emfd = pd.read_pickle('dictionaries/emfd_scoring.pkl')\n",
    "probabilites = [c for c in emfd.columns if c.endswith('_p')]\n",
    "foundations = ['care','fairness','loyalty','authority','sanctity']\n",
    "senti = [c for c in emfd.columns if c.endswith('_sent')]\n",
    "emfd = emfd.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['care.virtue', 'care.vice', 'authority.virtue', 'fairness.vice',\n",
       "       'fairness.virtue', 'loyalty.vice', 'loyalty.virtue',\n",
       "       'sanctity.virtue', 'authority.vice', 'sanctity.vice'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfd2_foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFD\n",
    "MFD = 'dictionaries/mft_original.dic'\n",
    "nummap = dict()\n",
    "mfd = dict()\n",
    "mfd_regex = dict()\n",
    "wordmode = True\n",
    "with open(MFD, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                mfd[ent[0]] = [nummap[e] for e in ent[1:]]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "                \n",
    "mfd_foundations = ['care.virtue', 'care.vice', 'authority.virtue', 'fairness.vice',\n",
    "       'fairness.virtue', 'loyalty.vice', 'loyalty.virtue',\n",
    "       'sanctity.virtue', 'authority.vice', 'sanctity.vice', 'moral']\n",
    "# convert vocab to compiled regex for comparison\n",
    "for v in mfd.keys():\n",
    "    mfd_regex[v] = re.compile(fnmatch.translate(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFD2.0 \n",
    "MFD2 = 'dictionaries/mfd2.0.dic'\n",
    "nummap = dict()\n",
    "mfd2 = dict()\n",
    "wordmode = True\n",
    "with open(MFD2, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                wordkey = ''.join([e for e in ent if e not in nummap.keys()])\n",
    "                mfd2[wordkey] = [nummap[e] for e in ent if e in nummap.keys()]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "mfd2 = pd.DataFrame.from_dict(mfd2).T\n",
    "mfd2_foundations = mfd2[0].unique()\n",
    "mfd2['foundation'] = mfd2[0]\n",
    "del mfd2[0]\n",
    "mfd2 = mfd2.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('data/mfdc_input.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build spaCy Scoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "    \n",
    "    '''Performs minimal preprocessing on textual document.\n",
    "    Steps include tokenization, lower-casing, and \n",
    "    stopword/punctuation/whitespace removal. \n",
    "    Returns list of processed tokens'''\n",
    "    \n",
    "    return  [x.lower_ for x in doc if x.lower_ not in stopwords and not x.is_punct and not x.is_digit and not x.is_quote and not x.like_num and not x.is_space] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_emfd(doc):\n",
    "    \n",
    "    '''Scores documents with the e-MFD.'''\n",
    "    \n",
    "    emfd_score = {k:0 for k in probabilites+senti}\n",
    "    moral_words = [ emfd[token] for token in doc if token in emfd.keys() ]\n",
    "    \n",
    "    for dic in moral_words:\n",
    "        emfd_score['care_p'] += dic['care_p']\n",
    "        emfd_score['fairness_p'] += dic['fairness_p']\n",
    "        emfd_score['loyalty_p'] += dic['loyalty_p']\n",
    "        emfd_score['authority_p'] += dic['authority_p']\n",
    "        emfd_score['sanctity_p'] += dic['sanctity_p']\n",
    "        \n",
    "        emfd_score['care_sent'] += dic['care_sent']\n",
    "        emfd_score['fairness_sent'] += dic['fairness_sent']\n",
    "        emfd_score['loyalty_sent'] += dic['loyalty_sent']\n",
    "        emfd_score['authority_sent'] += dic['authority_sent']\n",
    "        emfd_score['sanctity_sent'] += dic['sanctity_sent']\n",
    "    \n",
    "    emfd_score = {k:v/len(doc) for k,v in emfd_score.items()}\n",
    "    nonmoral_words = len(doc)-len(moral_words)\n",
    "    emfd_score['moral_nonmoral_ratio'] =  len(moral_words)/nonmoral_words \n",
    "    return emfd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mfd(doc):\n",
    "    \n",
    "    '''Scores documents with the original MFD.'''\n",
    "    \n",
    "    mfd_score = {k:0 for k in mfd_foundations}\n",
    "    moral_words = []\n",
    "    for token in doc:\n",
    "        for v in mfd_regex.keys():\n",
    "            if mfd_regex[v].match(token):\n",
    "                for f in mfd[v]:\n",
    "                    mfd_score[f] += 1\n",
    "    \n",
    "    mfd_score = {k:v/len(doc) for k,v in mfd_score.items()}\n",
    "    return mfd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mfd2(doc):\n",
    "    \n",
    "    '''Scores documents with the MFD2.'''\n",
    "    \n",
    "    mfd2_score = {k:0 for k in mfd2_foundations}\n",
    "    moral_words = [ mfd2[token]['foundation'] for token in doc if token in mfd2.keys() ]\n",
    "    f_counts = Counter(moral_words)\n",
    "    mfd2_score.update(f_counts)    \n",
    "    mfd2_score = {k:v/len(doc) for k,v in mfd2_score.items()}\n",
    "    return mfd2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_docs(csv, dic_type):\n",
    "    \n",
    "    '''Wrapper function that executes preprocessing and dictionary scoring. \n",
    "    dict_type specifies the dicitonary with which the documents should be scored.\n",
    "    Accepted values are: [emfd, mfd, mfd2]'''\n",
    "    \n",
    "    nlp = spacy.load('en', disable=['ner', 'parser', 'tagger'])\n",
    "    nlp.add_pipe(tokenizer, name=\"mfd_tokenizer\")\n",
    "    if dic_type == 'emfd':\n",
    "        nlp.add_pipe(score_emfd, name=\"score_emfd\", last=True)\n",
    "    elif dic_type == 'mfd':\n",
    "        nlp.add_pipe(score_mfd, name=\"score_mfd\", last=True)\n",
    "    elif dic_type == 'mfd2':\n",
    "        nlp.add_pipe(score_mfd2, name=\"score_mfd2\", last=True)\n",
    "    else:\n",
    "        print('Dictionary type not recognized. Available values are: emfd, mfd, mfd2')\n",
    "        return \n",
    "    scored_docs = csv[0].apply(lambda row: nlp(row))\n",
    "    df = scored_docs.apply(pd.Series)\n",
    "    if dic_type == 'emfd':\n",
    "        df['f_var'] = df[probabilites].var(axis=1)\n",
    "        df['sent_var'] = df[senti].var(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ent(token, entities):\n",
    "    '''High level function to match tokens to NER.\n",
    "    Do not include in nlp.pipe!'''\n",
    "    for k,v in entities.items():\n",
    "        if token in v:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaCy_NER(doc):\n",
    "    include_ents = ['PERSON','NORP', 'GPE']\n",
    "    entities = {ent.text:ent.text.split(' ') for ent in doc.ents if ent.label_ in include_ents}\n",
    "    cc_processed = {e:{'patient_words':[], 'agent_words':[], 'attribute_words':[],\n",
    "                  'patient_scores':[], 'agent_scores':[], 'attribute_scores':[]} for e in entities.keys()}\n",
    "    ner_out = {'cc_processed':cc_processed, 'doc':doc, 'entities':entities}\n",
    "    \n",
    "    return ner_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dependencies(ner_out):\n",
    "    doc = ner_out['doc']\n",
    "    cc_processed= ner_out['cc_processed']\n",
    "    entities = ner_out['entities']\n",
    "    \n",
    "    for token in doc:\n",
    "        if token not in stopwords:\n",
    "            if token.dep_ == 'nsubj' or  token.dep_ == 'ROOT':\n",
    "                word = token.head.text.lower()\n",
    "                if word in emfd.keys():\n",
    "                    try:\n",
    "                        cc_processed[find_ent(token.text, entities)]['agent_words'].append(word)\n",
    "                        cc_processed[find_ent(token.text, entities)]['agent_scores'].append(emfd[word])\n",
    "                    except KeyError as e:\n",
    "                        pass\n",
    "\n",
    "            if token.dep_ == 'dobj':\n",
    "                word = token.head.text.lower()\n",
    "                if word in emfd.keys():\n",
    "                    try:\n",
    "                        cc_processed[find_ent(token.text, entities)]['patient_words'].append(word)\n",
    "                        cc_processed[find_ent(token.text, entities)]['patient_scores'].append(emfd[word])\n",
    "                    except KeyError as e:\n",
    "                        pass\n",
    "\n",
    "            if token.dep_ == 'prep':\n",
    "                word = token.head.text.lower()\n",
    "                if word in emfd.keys():\n",
    "                    for child in token.children:\n",
    "                        try:\n",
    "                            cc_processed[find_ent(str(child), entities)]['patient_words'].append(word)\n",
    "                            cc_processed[find_ent(str(child), entities)]['patient_scores'].append(emfd[word])\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            if token.text == 'is':\n",
    "                try:\n",
    "                    children = list(token.children)\n",
    "                    word = children[1].lower()\n",
    "                    if word in emfd.keys():\n",
    "                        cc_processed[find_ent(str(children[0]),entities)]['attribute_words'].append(word)\n",
    "                        cc_processed[find_ent(str(children[0]),entities)]['attribute_scores'].append(emfd[word])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if token.dep_ == 'attr':\n",
    "                word = token.head.text.lower()\n",
    "                if word in emfd.keys():\n",
    "                    for child in token.children:\n",
    "                        try:\n",
    "                            cc_processed[find_ent(str(child), entities)]['attribute_words'].append(word)\n",
    "                            cc_processed[find_ent(str(child), entities)]['attribute_scores'].append(emfd[word])\n",
    "                        except:\n",
    "                            pass   \n",
    "\n",
    "            if token.dep_ == 'conj':\n",
    "                if str(doc[token.right_edge.i]) == '.' or str(doc[token.right_edge.i]) == '!' or str(doc[token.right_edge.i]) == '?':\n",
    "                    word = token.head.text.lower()\n",
    "                    if word in emfd.keys():\n",
    "                        try:\n",
    "                            cc_processed[find_ent(str(doc[token.right_edge.i-1]), entities)]['agent_words'].append(word)\n",
    "                            cc_processed[find_ent(str(doc[token.right_edge.i-1]), entities)]['agent_scores'].append(emfd[word])\n",
    "                        except:\n",
    "                            pass \n",
    "                else:\n",
    "                    word = token.head.text.lower()\n",
    "                    if word in emfd.keys():\n",
    "                        try:\n",
    "                            cc_processed[find_ent(str(token.right_edge), entities)]['agent_words'].append(word)\n",
    "                            cc_processed[find_ent(str(token.right_edge), entities)]['agent_scores'].append(emfd[word])\n",
    "                        except:\n",
    "                            pass \n",
    "        \n",
    "    return cc_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_ents(cc_processed):\n",
    "    \n",
    "    ''' Deletes entities w/out any related words.'''\n",
    "    \n",
    "    empty_ents = []\n",
    "    for k,v in cc_processed.items():\n",
    "        counter = 0\n",
    "        for k1, v1 in v.items():\n",
    "            counter += len(v1)\n",
    "        if counter == 0:\n",
    "            empty_ents.append(k)\n",
    "            \n",
    "    for e in empty_ents:\n",
    "        cc_processed.pop(e)\n",
    "        \n",
    "    return cc_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pat(cc_processed):\n",
    "    \n",
    "    '''Calculates the average emfd scores for \n",
    "    words in each PAT category. \n",
    "    Returns the final dataframe for each document. \n",
    "    This frame has three columns for detected  words in each PAT category and\n",
    "    10 columns for each PAT category capturing the mean emfd scores.\n",
    "    '''\n",
    "    \n",
    "    frames = []\n",
    "    for k,v in cc_processed.items():\n",
    "        agent = pd.DataFrame(v['agent_scores']).mean().to_frame().T\n",
    "        agent.columns = ['agent_' + str(col) for col in agent.columns]\n",
    "        \n",
    "        patient = pd.DataFrame(v['patient_scores']).mean().to_frame().T\n",
    "        patient.columns = ['patient_' + str(col) for col in patient.columns]\n",
    "        \n",
    "        attribute = pd.DataFrame(v['attribute_scores']).mean().to_frame().T\n",
    "        attribute.columns = ['attribute_' + str(col) for col in attribute.columns]\n",
    "        \n",
    "        df = pd.concat([agent, patient, attribute], axis=1)\n",
    "        df['NER'] = k\n",
    "        df['agent_words'] = ', '.join(v['agent_words'])\n",
    "        df['patient_words'] = ', '.join(v['patient_words'])\n",
    "        df['attribute_words'] = ', '.join((v['attribute_words']))\n",
    "        frames.append(df)\n",
    "    \n",
    "    df = pd.concat(frames)\n",
    "    words = ['agent_words','patient_words','attribute_words']\n",
    "    a_mf = [c for c in df.columns if c.startswith('agent') and c.endswith('p')]\n",
    "    a_sent = [c for c in df.columns if c.startswith('agent') and c.endswith('sent')]\n",
    "    \n",
    "    p_scores = [c for c in df.columns if c.startswith('patient') and c.endswith('p')]\n",
    "    p_sent = [c for c in df.columns if c.startswith('patient') and c.endswith('sent')]\n",
    "    \n",
    "    att_scores = [c for c in df.columns if c.startswith('attribute') and c.endswith('p')]\n",
    "    att_sent = [c for c in df.columns if c.startswith('attribute') and c.endswith('sent')]\n",
    "    \n",
    "    \n",
    "    return df[['NER']+words+a_mf+a_sent+p_scores+p_sent+att_scores+att_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(spaCy_NER, name='NER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(extract_dependencies, name='PAT extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(drop_ents, name='drop empty entities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(mean_pat, name='average PAT scores and return final df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f2f13118080>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f2f2d62bb28>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f2f2d62bb88>),\n",
       " ('NER', <function __main__.spaCy_NER(doc)>),\n",
       " ('PAT extraction', <function __main__.extract_dependencies(ner_out)>),\n",
       " ('drop empty entities', <function __main__.drop_ents(cc_processed)>),\n",
       " ('average PAT scores and return final df',\n",
       "  <function __main__.mean_pat(cc_processed)>)]"
      ]
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scored_docs = []\n",
    "for i, row in csv[0].head(2).iteritems():\n",
    "    scored_docs.append(nlp(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(scored_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>agent_words</th>\n",
       "      <th>patient_words</th>\n",
       "      <th>attribute_words</th>\n",
       "      <th>agent_authority_p</th>\n",
       "      <th>agent_care_p</th>\n",
       "      <th>agent_fairness_p</th>\n",
       "      <th>agent_loyalty_p</th>\n",
       "      <th>agent_sanctity_p</th>\n",
       "      <th>agent_authority_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_authority_p</th>\n",
       "      <th>patient_care_p</th>\n",
       "      <th>patient_fairness_p</th>\n",
       "      <th>patient_loyalty_p</th>\n",
       "      <th>patient_sanctity_p</th>\n",
       "      <th>patient_authority_sent</th>\n",
       "      <th>patient_care_sent</th>\n",
       "      <th>patient_fairness_sent</th>\n",
       "      <th>patient_loyalty_sent</th>\n",
       "      <th>patient_sanctity_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mosul</td>\n",
       "      <td></td>\n",
       "      <td>city, fight, fled, fleeing</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178824</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>0.113987</td>\n",
       "      <td>0.152080</td>\n",
       "      <td>0.090011</td>\n",
       "      <td>-0.193082</td>\n",
       "      <td>-0.389701</td>\n",
       "      <td>-0.259594</td>\n",
       "      <td>-0.257320</td>\n",
       "      <td>-0.368221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dominik Stillhart</td>\n",
       "      <td>said, said, said, said, said, said, said</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>-0.012368</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iraq</td>\n",
       "      <td></td>\n",
       "      <td>stronghold, staff</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125794</td>\n",
       "      <td>0.058190</td>\n",
       "      <td>0.071796</td>\n",
       "      <td>0.093219</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>-0.093667</td>\n",
       "      <td>-0.200642</td>\n",
       "      <td>-0.243302</td>\n",
       "      <td>-0.080500</td>\n",
       "      <td>-0.205412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geneva</td>\n",
       "      <td></td>\n",
       "      <td>headquarters</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-0.476700</td>\n",
       "      <td>-0.464767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.193840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Syria</td>\n",
       "      <td></td>\n",
       "      <td>operation</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>-0.147777</td>\n",
       "      <td>-0.350018</td>\n",
       "      <td>-0.078920</td>\n",
       "      <td>-0.026280</td>\n",
       "      <td>-0.202725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Korea</td>\n",
       "      <td>continues, seen</td>\n",
       "      <td>leader, strike, forces</td>\n",
       "      <td></td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.111145</td>\n",
       "      <td>0.074242</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.072211</td>\n",
       "      <td>-0.300540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146855</td>\n",
       "      <td>0.130324</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>0.109246</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>-0.145653</td>\n",
       "      <td>-0.201394</td>\n",
       "      <td>-0.066792</td>\n",
       "      <td>-0.054395</td>\n",
       "      <td>-0.135781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>believes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.142013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Gortney</td>\n",
       "      <td>said</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>-0.012368</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kim Jong Un</td>\n",
       "      <td>announced</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.070352</td>\n",
       "      <td>0.151220</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "      <td>hit</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.176136</td>\n",
       "      <td>0.073034</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>-0.122379</td>\n",
       "      <td>-0.100761</td>\n",
       "      <td>-0.108108</td>\n",
       "      <td>-0.337079</td>\n",
       "      <td>-0.242962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vincent Brooks</td>\n",
       "      <td>said</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>-0.012368</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NER                               agent_words  \\\n",
       "0              Mosul                                             \n",
       "0  Dominik Stillhart  said, said, said, said, said, said, said   \n",
       "0               Iraq                                             \n",
       "0             Geneva                                             \n",
       "0              Syria                                             \n",
       "0        North Korea                           continues, seen   \n",
       "0               U.S.                                  believes   \n",
       "0    William Gortney                                      said   \n",
       "0        Kim Jong Un                                 announced   \n",
       "0      United States                                             \n",
       "0     Vincent Brooks                                      said   \n",
       "\n",
       "                patient_words attribute_words  agent_authority_p  \\\n",
       "0  city, fight, fled, fleeing                                NaN   \n",
       "0                                                       0.045465   \n",
       "0           stronghold, staff                                NaN   \n",
       "0                headquarters                                NaN   \n",
       "0                   operation                                NaN   \n",
       "0      leader, strike, forces                           0.092593   \n",
       "0                                                       0.070175   \n",
       "0                                                       0.045465   \n",
       "0                                                       0.096939   \n",
       "0                         hit                                NaN   \n",
       "0                                                       0.045465   \n",
       "\n",
       "   agent_care_p  agent_fairness_p  agent_loyalty_p  agent_sanctity_p  \\\n",
       "0           NaN               NaN              NaN               NaN   \n",
       "0      0.044263          0.047012         0.049989          0.042168   \n",
       "0           NaN               NaN              NaN               NaN   \n",
       "0           NaN               NaN              NaN               NaN   \n",
       "0           NaN               NaN              NaN               NaN   \n",
       "0      0.111145          0.074242         0.090820          0.072211   \n",
       "0      0.063830          0.074766         0.117188          0.079208   \n",
       "0      0.044263          0.047012         0.049989          0.042168   \n",
       "0      0.070352          0.151220         0.092166          0.032967   \n",
       "0           NaN               NaN              NaN               NaN   \n",
       "0      0.044263          0.047012         0.049989          0.042168   \n",
       "\n",
       "   agent_authority_sent  ...  patient_authority_p  patient_care_p  \\\n",
       "0                   NaN  ...             0.178824        0.150470   \n",
       "0             -0.012368  ...                  NaN             NaN   \n",
       "0                   NaN  ...             0.125794        0.058190   \n",
       "0                   NaN  ...             0.018182        0.076923   \n",
       "0                   NaN  ...             0.116071        0.090164   \n",
       "0             -0.300540  ...             0.146855        0.130324   \n",
       "0              0.142013  ...                  NaN             NaN   \n",
       "0             -0.012368  ...                  NaN             NaN   \n",
       "0             -0.099532  ...                  NaN             NaN   \n",
       "0                   NaN  ...             0.089744        0.176136   \n",
       "0             -0.012368  ...                  NaN             NaN   \n",
       "\n",
       "   patient_fairness_p  patient_loyalty_p  patient_sanctity_p  \\\n",
       "0            0.113987           0.152080            0.090011   \n",
       "0                 NaN                NaN                 NaN   \n",
       "0            0.071796           0.093219            0.040350   \n",
       "0            0.046154           0.084746            0.034483   \n",
       "0            0.037879           0.071429            0.090909   \n",
       "0            0.074012           0.109246            0.100334   \n",
       "0                 NaN                NaN                 NaN   \n",
       "0                 NaN                NaN                 NaN   \n",
       "0                 NaN                NaN                 NaN   \n",
       "0            0.073034           0.077778            0.147887   \n",
       "0                 NaN                NaN                 NaN   \n",
       "\n",
       "   patient_authority_sent  patient_care_sent  patient_fairness_sent  \\\n",
       "0               -0.193082          -0.389701              -0.259594   \n",
       "0                     NaN                NaN                    NaN   \n",
       "0               -0.093667          -0.200642              -0.243302   \n",
       "0               -0.476700          -0.464767               0.000000   \n",
       "0               -0.147777          -0.350018              -0.078920   \n",
       "0               -0.145653          -0.201394              -0.066792   \n",
       "0                     NaN                NaN                    NaN   \n",
       "0                     NaN                NaN                    NaN   \n",
       "0                     NaN                NaN                    NaN   \n",
       "0               -0.122379          -0.100761              -0.108108   \n",
       "0                     NaN                NaN                    NaN   \n",
       "\n",
       "   patient_loyalty_sent  patient_sanctity_sent  \n",
       "0             -0.257320              -0.368221  \n",
       "0                   NaN                    NaN  \n",
       "0             -0.080500              -0.205412  \n",
       "0             -0.193840               0.000000  \n",
       "0             -0.026280              -0.202725  \n",
       "0             -0.054395              -0.135781  \n",
       "0                   NaN                    NaN  \n",
       "0                   NaN                    NaN  \n",
       "0                   NaN                    NaN  \n",
       "0             -0.337079              -0.242962  \n",
       "0                   NaN                    NaN  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement in AMorE! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    \n",
    "    '''Simple function to multiprocess functions on dataframe.\n",
    "    Adjust the Pool value to match your machine CPU capability'''\n",
    "    \n",
    "    df_split = np.array_split(df, cpu_count()-1)\n",
    "    pool = Pool(cpu_count()-1)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_sent(sentence):\n",
    "    \n",
    "    '''Function to preprocess sentences'''\n",
    "    \n",
    "    sentence = sentence.split(' ')\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "    sentence = [x.replace(\"'s\",'') for x in sentence]\n",
    "    for punc in punctuation:\n",
    "        sentence = [x.replace(punc,'') for x in sentence]\n",
    "    sentence = [x for x in sentence if x not in stopwords]\n",
    "    sentence = [x for x in sentence if x not in punctuation]\n",
    "    sentence = [x for x in sentence if len(x) > 2]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def score_emfd(csv):\n",
    "    \n",
    "    '''The main functuation for extracting moral information from a CSV \n",
    "    of input texts'''\n",
    "\n",
    "    scored_docs = []\n",
    "\n",
    "    for i, row in csv.iterrows(): \n",
    "        doc_id = i\n",
    "\n",
    "        # Turn document into spaCy DOC object\n",
    "        text = row.astype('unicode').values[0]\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Create list to store individual sentence scores\n",
    "        sentence_scores = []\n",
    "\n",
    "        # Initialize a variable to store the number of detected moral words \n",
    "        emfd_wordcount = 0 \n",
    "        non_moral_count = 0\n",
    "\n",
    "        # Start to loop over each sentence in a document\n",
    "        for s, sentence in enumerate(doc.sents):\n",
    "\n",
    "            # Run VADER to get sentence sentiment\n",
    "            sentiment = analyzer.polarity_scores(str(sentence))\n",
    "\n",
    "            # Preprocess sentence and turn into list of tokens \n",
    "            tokens = preproc_sent(str(sentence).strip())\n",
    "\n",
    "            # If an empty sentence is returned, skip this sentence\n",
    "            if len(tokens) == 0:\n",
    "                continue\n",
    "\n",
    "            # Initialize a matrix that has the 5 foundations + 5 sentiment categories as keys and that will store the scores for each detected word \n",
    "            emfd_score = pd.DataFrame(columns=[foundations+senti], index=range(0, len(tokens)))\n",
    "            emfd_score['vader_pos'] = sentiment['pos']\n",
    "            emfd_score['vader_neg'] = sentiment['neg']\n",
    "            emfd_score['vader_neu'] = sentiment['neu']\n",
    "            emfd_score['vader_pol'] = sentiment['compound']\n",
    "            emfd_score['word'] = ''\n",
    "\n",
    "            # Initiate scoring by looping over each token in the sentence\n",
    "            for x, token in enumerate(tokens):\n",
    "\n",
    "                # Is token in e-MFD?\n",
    "                if token in emfd.keys():\n",
    "                    # Yes: increase moral wordcount by 1\n",
    "                    emfd_wordcount += 1\n",
    "                    # In scoring matrix, insert words, foundation probabilities, and sentiment scores \n",
    "                    emfd_score.at[x, 'word'] = token\n",
    "                    emfd_score.at[x,'care'] = emfd[token]['care_p']\n",
    "                    emfd_score.at[x,'fairness'] = emfd[token]['fairness_p']\n",
    "                    emfd_score.at[x,'loyalty'] = emfd[token]['loyalty_p']\n",
    "                    emfd_score.at[x,'authority'] = emfd[token]['authority_p']\n",
    "                    emfd_score.at[x,'sanctity'] = emfd[token]['sanctity_p']\n",
    "                    \n",
    "                    emfd_score.at[x,'care_sent'] = emfd[token]['care_sent']\n",
    "                    emfd_score.at[x,'fairness_sent'] = emfd[token]['fairness_sent']\n",
    "                    emfd_score.at[x,'loyalty_sent'] = emfd[token]['loyalty_sent']\n",
    "                    emfd_score.at[x,'authority_sent'] = emfd[token]['authority_sent']\n",
    "                    emfd_score.at[x,'sanctity_sent'] = emfd[token]['sanctity_sent']\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    # Increase non-moral word count by 1\n",
    "                    non_moral_count += 1\n",
    "            \n",
    "            # Add indices \n",
    "            emfd_score['word_ix'] = emfd_score.index\n",
    "            emfd_score['sentence_ix'] = int(s)\n",
    "            emfd_score['document_ix'] = int(i)\n",
    "            emfd_score['moral_var'] = emfd_score[foundations].var(axis=1)\n",
    "            emfd_score['senti_var'] = emfd_score[senti].var(axis=1)\n",
    "            \n",
    "            \n",
    "#             emfd_score['shares'] = row['share_count']\n",
    "            sentence_scores.append(emfd_score)\n",
    "\n",
    "        # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "        sentences = pd.concat(sentence_scores)\n",
    "        sentences['moral_nonmoral_ratio'] = emfd_wordcount / non_moral_count\n",
    "        scored_docs.append(sentences)\n",
    "    \n",
    "    df = pd.concat(scored_docs)\n",
    "    df = df.dropna(how='any')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    \n",
    "    '''Simple function to multiprocess functions on dataframe.\n",
    "    Adjust the Pool value to match your machine CPU capability'''\n",
    "    \n",
    "    df_split = np.array_split(df, cpu_count()-2)\n",
    "    pool = Pool(cpu_count()-2)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_sent(sentence):\n",
    "    \n",
    "    '''Function to preprocess sentences'''\n",
    "    \n",
    "    sentence = sentence.split(' ')\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "    sentence = [x.replace(\"'s\",'') for x in sentence]\n",
    "    for punc in punctuation:\n",
    "        sentence = [x.replace(punc,'') for x in sentence]\n",
    "    sentence = [x for x in sentence if x not in stopwords]\n",
    "    sentence = [x for x in sentence if x not in punctuation]\n",
    "    sentence = [x for x in sentence if len(x) > 2]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def score_emfd(csv):\n",
    "    \n",
    "    '''The main functuation for extracting moral information from a CSV \n",
    "    of input texts'''\n",
    "\n",
    "    scored_docs = []\n",
    "\n",
    "    for i, row in csv.iterrows(): \n",
    "        doc_id = i\n",
    "\n",
    "        # Turn document into spaCy DOC object\n",
    "        text = row.astype('unicode').values[0]\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.text for token in doc]\n",
    "\n",
    "        # Initialize a variable to store the number of detected moral words \n",
    "        emfd_wordcount = 0 \n",
    "        non_moral_count = 0\n",
    "        \n",
    "        # Initialize a matrix that has the 5 foundations + 5 sentiment categories as keys and that will store the scores for each detected word \n",
    "        emfd_score = pd.DataFrame(columns=[foundations+senti], index=range(0, len(tokens)))\n",
    "\n",
    "        # Start to loop over each sentence in a document\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in e-MFD?\n",
    "            if token in emfd.keys():\n",
    "                # Yes: increase moral wordcount by 1\n",
    "                emfd_wordcount += 1\n",
    "                sentiment = analyzer.polarity_scores(str(token))\n",
    "                emfd_score['vader_pos'] = sentiment['pos']\n",
    "                emfd_score['vader_neg'] = sentiment['neg']\n",
    "                emfd_score['vader_neu'] = sentiment['neu']\n",
    "                emfd_score['vader_pol'] = sentiment['compound']\n",
    "                \n",
    "                # In scoring matrix, insert words, foundation probabilities, and sentiment scores \n",
    "                emfd_score.at[x,'care'] = emfd[token]['care_p']\n",
    "                emfd_score.at[x,'fairness'] = emfd[token]['fairness_p']\n",
    "                emfd_score.at[x,'loyalty'] = emfd[token]['loyalty_p']\n",
    "                emfd_score.at[x,'authority'] = emfd[token]['authority_p']\n",
    "                emfd_score.at[x,'sanctity'] = emfd[token]['sanctity_p']\n",
    "\n",
    "                emfd_score.at[x,'care_sent'] = emfd[token]['care_sent']\n",
    "                emfd_score.at[x,'fairness_sent'] = emfd[token]['fairness_sent']\n",
    "                emfd_score.at[x,'loyalty_sent'] = emfd[token]['loyalty_sent']\n",
    "                emfd_score.at[x,'authority_sent'] = emfd[token]['authority_sent']\n",
    "                emfd_score.at[x,'sanctity_sent'] = emfd[token]['sanctity_sent']\n",
    "                    \n",
    "            else:\n",
    "                # Increase non-moral word count by 1\n",
    "                non_moral_count += 1\n",
    "            \n",
    "        # Add indices \n",
    "        emfd_score['moral_var'] = emfd_score[foundations].var(axis=1)\n",
    "        emfd_score['senti_var'] = emfd_score[senti].var(axis=1)\n",
    "        emfd_score['moral_nonmoral_ratio'] = emfd_wordcount / non_moral_count\n",
    "        emfd_score = emfd_score.dropna(subset=[foundations], how='any')\n",
    "        emfd_score = pd.DataFrame(emfd_score.mean()).T\n",
    "        emfd_score.index = [i]\n",
    "            \n",
    "        scored_docs.append(emfd_score)\n",
    "    \n",
    "    df = pd.concat(scored_docs, axis=0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care_p</th>\n",
       "      <th>fairness_p</th>\n",
       "      <th>loyalty_p</th>\n",
       "      <th>authority_p</th>\n",
       "      <th>sanctity_p</th>\n",
       "      <th>care_sent</th>\n",
       "      <th>fairness_sent</th>\n",
       "      <th>loyalty_sent</th>\n",
       "      <th>authority_sent</th>\n",
       "      <th>sanctity_sent</th>\n",
       "      <th>moral_nonmoral_ratio</th>\n",
       "      <th>f_var</th>\n",
       "      <th>sent_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094813</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>0.069060</td>\n",
       "      <td>0.072408</td>\n",
       "      <td>0.058619</td>\n",
       "      <td>-0.109505</td>\n",
       "      <td>-0.088298</td>\n",
       "      <td>-0.070900</td>\n",
       "      <td>-0.074635</td>\n",
       "      <td>-0.076277</td>\n",
       "      <td>2.412500</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>0.054658</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.041654</td>\n",
       "      <td>-0.088256</td>\n",
       "      <td>-0.044245</td>\n",
       "      <td>-0.027897</td>\n",
       "      <td>-0.040930</td>\n",
       "      <td>-0.054355</td>\n",
       "      <td>1.553571</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>0.040456</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>-0.070804</td>\n",
       "      <td>-0.056856</td>\n",
       "      <td>-0.031816</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.043111</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045444</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.046669</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>-0.036410</td>\n",
       "      <td>-0.004051</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>-0.014176</td>\n",
       "      <td>-0.027695</td>\n",
       "      <td>1.057692</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052105</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>0.039107</td>\n",
       "      <td>-0.062859</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>-0.006178</td>\n",
       "      <td>-0.017404</td>\n",
       "      <td>-0.045186</td>\n",
       "      <td>1.331683</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.059822</td>\n",
       "      <td>0.058146</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>0.046878</td>\n",
       "      <td>-0.091002</td>\n",
       "      <td>-0.051419</td>\n",
       "      <td>-0.024035</td>\n",
       "      <td>-0.048596</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>1.201299</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080705</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.064227</td>\n",
       "      <td>0.058052</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>-0.002821</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>-0.014231</td>\n",
       "      <td>2.054217</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063438</td>\n",
       "      <td>0.053920</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.050844</td>\n",
       "      <td>0.044996</td>\n",
       "      <td>-0.072777</td>\n",
       "      <td>-0.043953</td>\n",
       "      <td>-0.030646</td>\n",
       "      <td>-0.042591</td>\n",
       "      <td>-0.074196</td>\n",
       "      <td>1.140777</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.077813</td>\n",
       "      <td>0.087277</td>\n",
       "      <td>0.070132</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>0.059522</td>\n",
       "      <td>-0.032490</td>\n",
       "      <td>0.030413</td>\n",
       "      <td>0.025335</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>-0.016338</td>\n",
       "      <td>2.188119</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.069137</td>\n",
       "      <td>0.053560</td>\n",
       "      <td>0.052671</td>\n",
       "      <td>0.051013</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>-0.060967</td>\n",
       "      <td>-0.061534</td>\n",
       "      <td>-0.034998</td>\n",
       "      <td>-0.027852</td>\n",
       "      <td>-0.067304</td>\n",
       "      <td>1.531034</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.066846</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.065525</td>\n",
       "      <td>0.048338</td>\n",
       "      <td>-0.048622</td>\n",
       "      <td>-0.022352</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>-0.019952</td>\n",
       "      <td>-0.025106</td>\n",
       "      <td>1.464052</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.065468</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.053297</td>\n",
       "      <td>0.051294</td>\n",
       "      <td>0.051246</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.051260</td>\n",
       "      <td>-0.022952</td>\n",
       "      <td>-0.040340</td>\n",
       "      <td>-0.066010</td>\n",
       "      <td>1.398907</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.046223</td>\n",
       "      <td>0.051433</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.038894</td>\n",
       "      <td>-0.036281</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.016696</td>\n",
       "      <td>1.220833</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.061588</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.052954</td>\n",
       "      <td>-0.032611</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>-0.019692</td>\n",
       "      <td>2.224138</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.062430</td>\n",
       "      <td>0.054839</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>-0.086005</td>\n",
       "      <td>-0.075578</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.035908</td>\n",
       "      <td>-0.067573</td>\n",
       "      <td>1.324910</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.056352</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>0.058291</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>-0.058594</td>\n",
       "      <td>-0.026706</td>\n",
       "      <td>-0.012876</td>\n",
       "      <td>-0.021843</td>\n",
       "      <td>-0.037287</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.072725</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>0.050755</td>\n",
       "      <td>0.042250</td>\n",
       "      <td>0.051443</td>\n",
       "      <td>-0.029995</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>0.048129</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>1.492063</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.047795</td>\n",
       "      <td>0.037961</td>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.030836</td>\n",
       "      <td>-0.044689</td>\n",
       "      <td>-0.023898</td>\n",
       "      <td>-0.019245</td>\n",
       "      <td>-0.024814</td>\n",
       "      <td>-0.042827</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.067845</td>\n",
       "      <td>0.048267</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>0.059780</td>\n",
       "      <td>0.044916</td>\n",
       "      <td>-0.108317</td>\n",
       "      <td>-0.073494</td>\n",
       "      <td>-0.058248</td>\n",
       "      <td>-0.078081</td>\n",
       "      <td>-0.092303</td>\n",
       "      <td>1.373626</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>-0.046216</td>\n",
       "      <td>-0.035613</td>\n",
       "      <td>-0.002870</td>\n",
       "      <td>-0.016460</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>1.885965</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.073031</td>\n",
       "      <td>0.055996</td>\n",
       "      <td>0.057099</td>\n",
       "      <td>0.060047</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>-0.127150</td>\n",
       "      <td>-0.094323</td>\n",
       "      <td>-0.081098</td>\n",
       "      <td>-0.082012</td>\n",
       "      <td>-0.107221</td>\n",
       "      <td>1.503226</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.079156</td>\n",
       "      <td>0.061871</td>\n",
       "      <td>0.065369</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>-0.044149</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.015414</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>2.281481</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.057354</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0.048573</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.049632</td>\n",
       "      <td>-0.040416</td>\n",
       "      <td>-0.004889</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>-0.006759</td>\n",
       "      <td>-0.023390</td>\n",
       "      <td>1.214815</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.071852</td>\n",
       "      <td>0.084351</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.071503</td>\n",
       "      <td>0.063342</td>\n",
       "      <td>-0.078037</td>\n",
       "      <td>-0.033553</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>-0.023273</td>\n",
       "      <td>-0.043724</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.071625</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.054142</td>\n",
       "      <td>0.059238</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>-0.118041</td>\n",
       "      <td>-0.084943</td>\n",
       "      <td>-0.078242</td>\n",
       "      <td>-0.068949</td>\n",
       "      <td>-0.102593</td>\n",
       "      <td>1.437086</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>0.033329</td>\n",
       "      <td>0.035162</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>-0.040838</td>\n",
       "      <td>-0.018401</td>\n",
       "      <td>-0.003818</td>\n",
       "      <td>-0.014695</td>\n",
       "      <td>-0.026045</td>\n",
       "      <td>0.639286</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.063152</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.048877</td>\n",
       "      <td>0.052932</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>-0.055234</td>\n",
       "      <td>-0.027383</td>\n",
       "      <td>-0.015161</td>\n",
       "      <td>-0.033881</td>\n",
       "      <td>-0.045422</td>\n",
       "      <td>1.222749</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.067850</td>\n",
       "      <td>0.070219</td>\n",
       "      <td>0.056429</td>\n",
       "      <td>0.064780</td>\n",
       "      <td>0.046558</td>\n",
       "      <td>-0.021856</td>\n",
       "      <td>-0.010496</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>1.792035</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.046246</td>\n",
       "      <td>0.047320</td>\n",
       "      <td>0.043961</td>\n",
       "      <td>0.042815</td>\n",
       "      <td>-0.029783</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.009173</td>\n",
       "      <td>-0.008344</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.045376</td>\n",
       "      <td>0.043502</td>\n",
       "      <td>0.041505</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.041216</td>\n",
       "      <td>-0.034767</td>\n",
       "      <td>-0.017213</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>-0.009970</td>\n",
       "      <td>-0.020283</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.071428</td>\n",
       "      <td>0.063892</td>\n",
       "      <td>0.065015</td>\n",
       "      <td>0.060477</td>\n",
       "      <td>-0.048467</td>\n",
       "      <td>-0.007499</td>\n",
       "      <td>-0.001757</td>\n",
       "      <td>-0.021719</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>2.335443</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>0.086508</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.061098</td>\n",
       "      <td>0.060490</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>-0.108388</td>\n",
       "      <td>-0.082152</td>\n",
       "      <td>-0.052909</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>-0.074330</td>\n",
       "      <td>1.734177</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>0.062766</td>\n",
       "      <td>0.049919</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>-0.031181</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>-0.004211</td>\n",
       "      <td>-0.016054</td>\n",
       "      <td>-0.024312</td>\n",
       "      <td>1.147368</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>0.041189</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>0.040176</td>\n",
       "      <td>0.034007</td>\n",
       "      <td>-0.032353</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.014333</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>0.888535</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.034712</td>\n",
       "      <td>0.035759</td>\n",
       "      <td>0.026309</td>\n",
       "      <td>-0.043261</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>-0.007243</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>-0.018971</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>0.071418</td>\n",
       "      <td>0.072627</td>\n",
       "      <td>0.060697</td>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.053373</td>\n",
       "      <td>-0.019033</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.014953</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0.064913</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.062122</td>\n",
       "      <td>0.060679</td>\n",
       "      <td>0.051277</td>\n",
       "      <td>-0.032841</td>\n",
       "      <td>-0.012049</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>-0.006163</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>1.709877</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>0.053488</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>0.041470</td>\n",
       "      <td>-0.064525</td>\n",
       "      <td>-0.031324</td>\n",
       "      <td>-0.017811</td>\n",
       "      <td>-0.015019</td>\n",
       "      <td>-0.024922</td>\n",
       "      <td>1.242958</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.053432</td>\n",
       "      <td>0.064736</td>\n",
       "      <td>0.056293</td>\n",
       "      <td>0.071836</td>\n",
       "      <td>0.044989</td>\n",
       "      <td>-0.049457</td>\n",
       "      <td>-0.031197</td>\n",
       "      <td>-0.027029</td>\n",
       "      <td>-0.027105</td>\n",
       "      <td>-0.036219</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>0.059511</td>\n",
       "      <td>0.055131</td>\n",
       "      <td>0.053439</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.045824</td>\n",
       "      <td>-0.045176</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>0.020055</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>-0.001711</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0.060750</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.053855</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.038569</td>\n",
       "      <td>-0.031105</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>-0.021077</td>\n",
       "      <td>1.565217</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0.069194</td>\n",
       "      <td>0.066885</td>\n",
       "      <td>0.054648</td>\n",
       "      <td>0.062666</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>-0.096850</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>-0.063900</td>\n",
       "      <td>-0.072678</td>\n",
       "      <td>1.550336</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>-0.026055</td>\n",
       "      <td>-0.009582</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-0.011327</td>\n",
       "      <td>-0.028891</td>\n",
       "      <td>0.662687</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0.041429</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.043383</td>\n",
       "      <td>0.042446</td>\n",
       "      <td>0.037366</td>\n",
       "      <td>-0.051727</td>\n",
       "      <td>-0.039916</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.035421</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0.054988</td>\n",
       "      <td>0.056737</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.059134</td>\n",
       "      <td>0.045314</td>\n",
       "      <td>-0.018596</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>1.305389</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.072927</td>\n",
       "      <td>0.055875</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>0.064136</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>-0.105483</td>\n",
       "      <td>-0.078743</td>\n",
       "      <td>-0.059440</td>\n",
       "      <td>-0.074502</td>\n",
       "      <td>-0.086651</td>\n",
       "      <td>1.583732</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.067490</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.055180</td>\n",
       "      <td>0.061868</td>\n",
       "      <td>0.046737</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.059389</td>\n",
       "      <td>-0.045519</td>\n",
       "      <td>-0.060446</td>\n",
       "      <td>-0.081037</td>\n",
       "      <td>1.496296</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.069143</td>\n",
       "      <td>0.076076</td>\n",
       "      <td>0.060908</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.054387</td>\n",
       "      <td>-0.012333</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>1.798942</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.084220</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.058524</td>\n",
       "      <td>0.057069</td>\n",
       "      <td>0.055733</td>\n",
       "      <td>-0.088893</td>\n",
       "      <td>-0.059259</td>\n",
       "      <td>-0.042319</td>\n",
       "      <td>-0.050020</td>\n",
       "      <td>-0.066938</td>\n",
       "      <td>1.635036</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.051803</td>\n",
       "      <td>0.053723</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>0.062744</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>-0.046783</td>\n",
       "      <td>-0.021831</td>\n",
       "      <td>-0.008537</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>1.278302</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.069346</td>\n",
       "      <td>0.069249</td>\n",
       "      <td>0.069032</td>\n",
       "      <td>0.070592</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>-0.075901</td>\n",
       "      <td>-0.032171</td>\n",
       "      <td>-0.016057</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>-0.044495</td>\n",
       "      <td>1.806867</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.034062</td>\n",
       "      <td>-0.049609</td>\n",
       "      <td>-0.030839</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>1.294444</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.059907</td>\n",
       "      <td>0.059066</td>\n",
       "      <td>0.057657</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>-0.054857</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>-0.012140</td>\n",
       "      <td>-0.016652</td>\n",
       "      <td>-0.028234</td>\n",
       "      <td>1.305019</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.065910</td>\n",
       "      <td>0.071955</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.056905</td>\n",
       "      <td>0.050529</td>\n",
       "      <td>-0.109492</td>\n",
       "      <td>-0.081389</td>\n",
       "      <td>-0.077059</td>\n",
       "      <td>-0.074252</td>\n",
       "      <td>-0.080302</td>\n",
       "      <td>1.218182</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.049148</td>\n",
       "      <td>0.050114</td>\n",
       "      <td>0.051089</td>\n",
       "      <td>0.051386</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>-0.038192</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>1.155039</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.064049</td>\n",
       "      <td>0.056077</td>\n",
       "      <td>0.057461</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.048737</td>\n",
       "      <td>-0.075694</td>\n",
       "      <td>-0.056891</td>\n",
       "      <td>-0.043571</td>\n",
       "      <td>-0.048883</td>\n",
       "      <td>-0.061162</td>\n",
       "      <td>1.482558</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.070067</td>\n",
       "      <td>0.072128</td>\n",
       "      <td>0.069473</td>\n",
       "      <td>0.071204</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>-0.023009</td>\n",
       "      <td>-0.005050</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.052483</td>\n",
       "      <td>0.054696</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>0.051964</td>\n",
       "      <td>0.038756</td>\n",
       "      <td>-0.025954</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.020284</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>-0.006632</td>\n",
       "      <td>1.245283</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.070058</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.059046</td>\n",
       "      <td>0.060413</td>\n",
       "      <td>0.048331</td>\n",
       "      <td>-0.032009</td>\n",
       "      <td>-0.010730</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>-0.015759</td>\n",
       "      <td>1.643836</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.070797</td>\n",
       "      <td>0.062632</td>\n",
       "      <td>0.063909</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>-0.104485</td>\n",
       "      <td>-0.061618</td>\n",
       "      <td>-0.048991</td>\n",
       "      <td>-0.071554</td>\n",
       "      <td>-0.064542</td>\n",
       "      <td>1.762590</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        care_p  fairness_p  loyalty_p  authority_p  sanctity_p  care_sent  \\\n",
       "0     0.094813    0.073032   0.069060     0.072408    0.058619  -0.109505   \n",
       "1     0.067849    0.052367   0.054658     0.059176    0.041654  -0.088256   \n",
       "2     0.049164    0.045042   0.040456     0.041374    0.038014  -0.070804   \n",
       "3     0.045444    0.043486   0.042962     0.046669    0.035920  -0.036410   \n",
       "4     0.052105    0.049796   0.052589     0.051535    0.039107  -0.062859   \n",
       "5     0.057937    0.059822   0.058146     0.057434    0.046878  -0.091002   \n",
       "6     0.080705    0.075128   0.063355     0.064227    0.058052  -0.013425   \n",
       "7     0.063438    0.053920   0.047825     0.050844    0.044996  -0.072777   \n",
       "8     0.077813    0.087277   0.070132     0.061160    0.059522  -0.032490   \n",
       "9     0.069137    0.053560   0.052671     0.051013    0.049883  -0.060967   \n",
       "10    0.061232    0.066846   0.061806     0.065525    0.048338  -0.048622   \n",
       "11    0.065468    0.062012   0.053297     0.051294    0.051246  -0.085798   \n",
       "12    0.046223    0.051433   0.046963     0.047382    0.038894  -0.036281   \n",
       "13    0.066663    0.064888   0.061588     0.068062    0.052954  -0.032611   \n",
       "14    0.069360    0.062430   0.054839     0.054697    0.050129  -0.086005   \n",
       "15    0.056352    0.053566   0.058291     0.066954    0.045647  -0.058594   \n",
       "16    0.072725    0.056831   0.050755     0.042250    0.051443  -0.029995   \n",
       "17    0.047795    0.037961   0.035490     0.037181    0.030836  -0.044689   \n",
       "18    0.067845    0.048267   0.053529     0.059780    0.044916  -0.108317   \n",
       "19    0.056991    0.059243   0.055914     0.055942    0.048878  -0.046216   \n",
       "20    0.073031    0.055996   0.057099     0.060047    0.048427  -0.127150   \n",
       "21    0.065705    0.079156   0.061871     0.065369    0.051860  -0.044149   \n",
       "22    0.057354    0.051077   0.048573     0.049629    0.049632  -0.040416   \n",
       "23    0.071852    0.084351   0.067431     0.071503    0.063342  -0.078037   \n",
       "24    0.071625    0.062157   0.054142     0.059238    0.049536  -0.118041   \n",
       "25    0.032584    0.035103   0.033329     0.035162    0.028416  -0.040838   \n",
       "26    0.063152    0.054113   0.048877     0.052932    0.043594  -0.055234   \n",
       "27    0.067850    0.070219   0.056429     0.064780    0.046558  -0.021856   \n",
       "28    0.053139    0.046246   0.047320     0.043961    0.042815  -0.029783   \n",
       "29    0.045376    0.043502   0.041505     0.042000    0.041216  -0.034767   \n",
       "...        ...         ...        ...          ...         ...        ...   \n",
       "1955  0.079941    0.071428   0.063892     0.065015    0.060477  -0.048467   \n",
       "1956  0.086508    0.059844   0.061098     0.060490    0.053031  -0.108388   \n",
       "1957  0.062766    0.049919   0.046111     0.041698    0.043451  -0.031181   \n",
       "1958  0.041189    0.042910   0.038614     0.040176    0.034007  -0.032353   \n",
       "1959  0.040987    0.038346   0.034712     0.035759    0.026309  -0.043261   \n",
       "1960  0.071418    0.072627   0.060697     0.059840    0.053373  -0.019033   \n",
       "1961  0.064913    0.066271   0.062122     0.060679    0.051277  -0.032841   \n",
       "1962  0.053488    0.051135   0.059541     0.063574    0.041470  -0.064525   \n",
       "1963  0.053432    0.064736   0.056293     0.071836    0.044989  -0.049457   \n",
       "1964  0.059511    0.055131   0.053439     0.053463    0.045824  -0.045176   \n",
       "1965  0.060750    0.057600   0.053855     0.056218    0.038569  -0.031105   \n",
       "1966  0.069194    0.066885   0.054648     0.062666    0.049365  -0.096850   \n",
       "1967  0.038864    0.037049   0.035008     0.032876    0.031743  -0.026055   \n",
       "1968  0.041429    0.042660   0.043383     0.042446    0.037366  -0.051727   \n",
       "1969  0.054988    0.056737   0.055868     0.059134    0.045314  -0.018596   \n",
       "1970  0.072927    0.055875   0.059353     0.064136    0.045134  -0.105483   \n",
       "1971  0.067490    0.075900   0.055180     0.061868    0.046737  -0.096801   \n",
       "1972  0.069143    0.076076   0.060908     0.064036    0.054387  -0.012333   \n",
       "1973  0.084220    0.063023   0.058524     0.057069    0.055733  -0.088893   \n",
       "1974  0.051803    0.053723   0.061895     0.062744    0.045792  -0.046783   \n",
       "1975  0.069346    0.069249   0.069032     0.070592    0.056666  -0.075901   \n",
       "1976  0.036662    0.041152   0.044227     0.050654    0.034062  -0.049609   \n",
       "1977  0.059907    0.059066   0.057657     0.056398    0.049978  -0.054857   \n",
       "1978  0.065910    0.071955   0.054496     0.056905    0.050529  -0.109492   \n",
       "1979  0.049148    0.050114   0.051089     0.051386    0.041280  -0.038192   \n",
       "1980  0.064049    0.056077   0.057461     0.067467    0.048737  -0.075694   \n",
       "1981  0.070067    0.072128   0.069473     0.071204    0.060948  -0.023009   \n",
       "1982  0.052483    0.054696   0.053403     0.051964    0.038756  -0.025954   \n",
       "1983  0.070058    0.059933   0.059046     0.060413    0.048331  -0.032009   \n",
       "1984  0.070797    0.062632   0.063909     0.066873    0.050033  -0.104485   \n",
       "\n",
       "      fairness_sent  loyalty_sent  authority_sent  sanctity_sent  \\\n",
       "0         -0.088298     -0.070900       -0.074635      -0.076277   \n",
       "1         -0.044245     -0.027897       -0.040930      -0.054355   \n",
       "2         -0.056856     -0.031816       -0.041140      -0.043111   \n",
       "3         -0.004051      0.009884       -0.014176      -0.027695   \n",
       "4         -0.032623     -0.006178       -0.017404      -0.045186   \n",
       "5         -0.051419     -0.024035       -0.048596      -0.055692   \n",
       "6         -0.002821      0.017426        0.004184      -0.014231   \n",
       "7         -0.043953     -0.030646       -0.042591      -0.074196   \n",
       "8          0.030413      0.025335       -0.014331      -0.016338   \n",
       "9         -0.061534     -0.034998       -0.027852      -0.067304   \n",
       "10        -0.022352     -0.005354       -0.019952      -0.025106   \n",
       "11        -0.051260     -0.022952       -0.040340      -0.066010   \n",
       "12        -0.003193     -0.000731       -0.003704      -0.016696   \n",
       "13         0.005673      0.019130        0.001765      -0.019692   \n",
       "14        -0.075578     -0.043042       -0.035908      -0.067573   \n",
       "15        -0.026706     -0.012876       -0.021843      -0.037287   \n",
       "16         0.020537      0.048129        0.013812      -0.010111   \n",
       "17        -0.023898     -0.019245       -0.024814      -0.042827   \n",
       "18        -0.073494     -0.058248       -0.078081      -0.092303   \n",
       "19        -0.035613     -0.002870       -0.016460      -0.029114   \n",
       "20        -0.094323     -0.081098       -0.082012      -0.107221   \n",
       "21         0.002945     -0.000863       -0.015414      -0.014177   \n",
       "22        -0.004889      0.008471       -0.006759      -0.023390   \n",
       "23        -0.033553     -0.003981       -0.023273      -0.043724   \n",
       "24        -0.084943     -0.078242       -0.068949      -0.102593   \n",
       "25        -0.018401     -0.003818       -0.014695      -0.026045   \n",
       "26        -0.027383     -0.015161       -0.033881      -0.045422   \n",
       "27        -0.010496      0.008671        0.003190       0.000123   \n",
       "28         0.003719      0.009173       -0.008344      -0.005901   \n",
       "29        -0.017213      0.013192       -0.009970      -0.020283   \n",
       "...             ...           ...             ...            ...   \n",
       "1955      -0.007499     -0.001757       -0.021719      -0.026013   \n",
       "1956      -0.082152     -0.052909       -0.073639      -0.074330   \n",
       "1957      -0.002731     -0.004211       -0.016054      -0.024312   \n",
       "1958       0.009931      0.014333       -0.007455      -0.007044   \n",
       "1959      -0.014612     -0.007243       -0.012980      -0.018971   \n",
       "1960       0.008837      0.022414        0.014953      -0.000213   \n",
       "1961      -0.012049      0.007964       -0.006163      -0.015403   \n",
       "1962      -0.031324     -0.017811       -0.015019      -0.024922   \n",
       "1963      -0.031197     -0.027029       -0.027105      -0.036219   \n",
       "1964      -0.005487      0.020055        0.003605      -0.001711   \n",
       "1965       0.009829      0.008455        0.005666      -0.021077   \n",
       "1966      -0.054545     -0.040407       -0.063900      -0.072678   \n",
       "1967      -0.009582      0.003518       -0.011327      -0.028891   \n",
       "1968      -0.039916     -0.015724       -0.016570      -0.035421   \n",
       "1969       0.000588      0.005533        0.012499       0.010354   \n",
       "1970      -0.078743     -0.059440       -0.074502      -0.086651   \n",
       "1971      -0.059389     -0.045519       -0.060446      -0.081037   \n",
       "1972      -0.002333      0.022197        0.001788      -0.007472   \n",
       "1973      -0.059259     -0.042319       -0.050020      -0.066938   \n",
       "1974      -0.021831     -0.008537       -0.010472      -0.018005   \n",
       "1975      -0.032171     -0.016057       -0.026956      -0.044495   \n",
       "1976      -0.030839      0.008065       -0.004661      -0.005400   \n",
       "1977      -0.025925     -0.012140       -0.016652      -0.028234   \n",
       "1978      -0.081389     -0.077059       -0.074252      -0.080302   \n",
       "1979      -0.004801      0.013110        0.001846      -0.011801   \n",
       "1980      -0.056891     -0.043571       -0.048883      -0.061162   \n",
       "1981      -0.005050      0.009205       -0.005336      -0.004639   \n",
       "1982       0.000948      0.020284        0.001887      -0.006632   \n",
       "1983      -0.010730      0.009998        0.004984      -0.015759   \n",
       "1984      -0.061618     -0.048991       -0.071554      -0.064542   \n",
       "\n",
       "      moral_nonmoral_ratio     f_var  sent_var  \n",
       "0                 2.412500  0.000174  0.000247  \n",
       "1                 1.553571  0.000092  0.000520  \n",
       "2                 0.767442  0.000019  0.000232  \n",
       "3                 1.057692  0.000017  0.000340  \n",
       "4                 1.331683  0.000032  0.000501  \n",
       "5                 1.201299  0.000027  0.000576  \n",
       "6                 2.054217  0.000087  0.000174  \n",
       "7                 1.140777  0.000051  0.000383  \n",
       "8                 2.188119  0.000135  0.000771  \n",
       "9                 1.531034  0.000062  0.000317  \n",
       "10                1.464052  0.000054  0.000243  \n",
       "11                1.398907  0.000044  0.000578  \n",
       "12                1.220833  0.000021  0.000221  \n",
       "13                2.224138  0.000036  0.000430  \n",
       "14                1.324910  0.000058  0.000458  \n",
       "15                1.500000  0.000060  0.000308  \n",
       "16                1.492063  0.000128  0.000893  \n",
       "17                0.775510  0.000039  0.000139  \n",
       "18                1.373626  0.000084  0.000363  \n",
       "19                1.885965  0.000015  0.000284  \n",
       "20                1.503226  0.000081  0.000372  \n",
       "21                2.281481  0.000096  0.000343  \n",
       "22                1.214815  0.000012  0.000356  \n",
       "23                2.684211  0.000062  0.000755  \n",
       "24                1.437086  0.000071  0.000388  \n",
       "25                0.639286  0.000008  0.000190  \n",
       "26                1.222749  0.000052  0.000243  \n",
       "27                1.792035  0.000094  0.000148  \n",
       "28                1.080745  0.000016  0.000224  \n",
       "29                0.868132  0.000003  0.000309  \n",
       "...                    ...       ...       ...  \n",
       "1955              2.335443  0.000059  0.000333  \n",
       "1956              1.734177  0.000166  0.000401  \n",
       "1957              1.147368  0.000071  0.000154  \n",
       "1958              0.888535  0.000011  0.000338  \n",
       "1959              0.919753  0.000031  0.000195  \n",
       "1960              1.951220  0.000067  0.000255  \n",
       "1961              1.709877  0.000035  0.000220  \n",
       "1962              1.242958  0.000072  0.000397  \n",
       "1963              1.714286  0.000107  0.000087  \n",
       "1964              1.560000  0.000024  0.000581  \n",
       "1965              1.565217  0.000075  0.000363  \n",
       "1966              1.550336  0.000070  0.000447  \n",
       "1967              0.662687  0.000009  0.000175  \n",
       "1968              0.993865  0.000006  0.000242  \n",
       "1969              1.305389  0.000028  0.000155  \n",
       "1970              1.583732  0.000105  0.000286  \n",
       "1971              1.496296  0.000125  0.000409  \n",
       "1972              1.798942  0.000068  0.000177  \n",
       "1973              1.635036  0.000139  0.000321  \n",
       "1974              1.278302  0.000051  0.000235  \n",
       "1975              1.806867  0.000034  0.000527  \n",
       "1976              1.294444  0.000042  0.000542  \n",
       "1977              1.305019  0.000016  0.000276  \n",
       "1978              1.218182  0.000077  0.000203  \n",
       "1979              1.155039  0.000018  0.000370  \n",
       "1980              1.482558  0.000053  0.000153  \n",
       "1981              2.312500  0.000020  0.000131  \n",
       "1982              1.245283  0.000042  0.000279  \n",
       "1983              1.643836  0.000059  0.000284  \n",
       "1984              1.762590  0.000061  0.000433  \n",
       "\n",
       "[1985 rows x 13 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'assault': {'nsubj': 'take'}, 'city': {'dobj': 'retake'}, 'take': [assault, could, months, ,, prompting, .], 'months': {'dobj': 'take'}, 'civilians': {'dobj': 'prompting'}, 'official': {'nsubj': 'told'}, 'Reuters': {'dobj': 'told'}}\n"
     ]
    }
   ],
   "source": [
    "test = 'The government\\'s assault to retake the city of Mosul could take months, prompting more and more civilians to try to flee to avoid being trapped between frontlines, a senior official of the International Committee of the Red Cross told Reuters.'\n",
    "doc = nlp(test)\n",
    "for s, sentence in enumerate(doc.sents):\n",
    "    sentiment = analyzer.polarity_scores(str(sentence))\n",
    "    # Preprocess sentence and turn into list of tokens \n",
    "    tokens = preproc_sent(str(sentence).strip())\n",
    "    \n",
    "    # Perform dependency parsing TODO: add variable to toggle dep. parsing\n",
    "    dep_dic = {}\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ =='PERSON' or token.dep_ =='GPE' or token.dep_ =='NORP':\n",
    "            dep_dic[token.text] = {token.dep_:token.head.text}  \n",
    "        if token.dep_ =='ROOT' and [child in dep_dic.keys() for child in token.children]:\n",
    "            dep_dic[token.text] = [child for child in token.children]\n",
    "    print(dep_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Iraqi government\\'s assault to retake the city of Mosul could take months, prompting more and more civilians to try to flee to avoid being trapped between frontlines, a senior official of the International Committee of the Red Cross told Reuters.\\n\\nA growing number of wounded, more than 100 on some days, are  emerging from rural areas surrounding the city of one million that is held by Islamic State forces, said Dominik Stillhart, director of ICRC operations worldwide.\\n\\n\"What we see now on the ground is indeed that the fight in Mosul is not just going to stop anytime soon because the resistance is very strong,\" Stillhart, back from visiting Iraq, said in an interview on Thursday at ICRC headquarters in Geneva.\\n\\n\"It is likely that we will see long, drawn-out fighting with very serious suffering of a population that will once again be caught between two frontlines,\" he said. \"It is reasonable to expect that this is going to take weeks if not months.\"\\n\\nMore than six weeks into the offensive against Islamic State\\'s last major city stronghold in Iraq, the army is trying to dislodge militants dug in among civilians in the eastern districts, the only side Iraqi troops have been able to breach.\\n\\n\"The original idea of the government as they told me, government officials, is that people should stay in their houses as much as possible,\" Stillhart said. \"But of course the longer the fighting will be drawn out, the more people will probably try to flee.\"\\n\\nSome 70,000 people had been displaced so far, a relatively low number that he said suggested the Iraqi military was giving consideration to protecting the civilian population.\\n\\n\"But looking at what is happening elsewhere in the Middle East, we are of course concerned about yet another situation where we have intense urban warfare with large-scale destruction which will of course heavily impact on the civilian population.\"\\n\\nThe ICRC is focusing on providing food and shelter material to civilians who have fled Mosul, and on water and sanitation projects, Stillhart said.\\n\\nSCREENING CENTERS\\n\\nIraqi officials have allowed ICRC officials to monitor the condition of those fleeing Mosul who are questioned or detained, he said. \"We have free access to these screening centers, we can monitor the screening.\"\\n\\nICRC findings on treatment and detention conditions are confidential, as with their prison visits across Iraq.\\n\\nThe ICRC deploys nearly 1,000 staff in Iraq, its second largest operation worldwide after Syria. Its first full surgical team of six will start working next week in Shikhan hospital, north of Mosul, Stillhart said.\\n\\nIt has provided first aid training to 900 health workers and supplied hospitals with dressing kits and surgical instruments.\\n\\n\"But it is true, as soon as the fighting intensifies and there are big battles, that there are situations where individual hospitals will have difficulties to cope with the number of wounded,\" Stillhart said.\\n\\nIslamic State forces are alleged to have used chemical weapons earlier this year in northern Iraq.\\n\\n\"We have trained and equipped our staff for possible small-scale use of chemical weapons, but we have also prepared some of these medical facilities with training and equipment to receive people affected by chemical weapons,\" Stillhart said.\\n\\n(Reporting by Stephanie Nebehay)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head(1)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
